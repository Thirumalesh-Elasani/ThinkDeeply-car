{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "from __future__ import absolute_import\n", 
        "from __future__ import division\n", 
        "from __future__ import print_function\n", 
        "\n", 
        "import sys\n", 
        "\n", 
        "import numpy as np\n", 
        "import tensorflow as tf\n", 
        "\n", 
        "\n", 
        "# The operation used to print out the configuration\n", 
        "def print_configuration_op(FLAGS):\n", 
        "    print('[Configurations]:')\n", 
        "    # pdb.set_trace()\n", 
        "    for name in FLAGS.__flags.keys():\n", 
        "        value = getattr(FLAGS, name)\n", 
        "        if type(value) == float:\n", 
        "            print('\\t%s: %f' % (name, value))\n", 
        "        elif type(value) == int:\n", 
        "            print('\\t%s: %d' % (name, value))\n", 
        "        elif type(value) == str:\n", 
        "            print('\\t%s: %s' % (name, value))\n", 
        "        elif type(value) == bool:\n", 
        "            print('\\t%s: %s' % (name, value))\n", 
        "        else:\n", 
        "            print('\\t%s: %s' % (name, value))\n", 
        "\n", 
        "    print('End of configuration')\n", 
        "\n", 
        "\n", 
        "def update(it, image, image_d, image_white, axis):\n", 
        "    image_d = tf.cond(tf.less(tf.random.uniform([], minval=0, maxval=1), 0.5),\n", 
        "                      lambda: tf.concat([image_d, image_white], axis=axis),\n", 
        "                      lambda: tf.concat([image_d, image], axis=axis))\n", 
        "    it = it + 1\n", 
        "\n", 
        "    return it, image, image_d, image_white, axis\n", 
        "\n", 
        "\n", 
        "def duplicate(image, times, axis_mode=\"height\", mode=\"train\"):\n", 
        "    times = tf.cast(times, dtype=tf.int32)\n", 
        "    if axis_mode == \"height\":\n", 
        "        axis = tf.constant(0)\n", 
        "        tile_shape = (times, 1, 1)\n", 
        "    elif axis_mode == \"width\":\n", 
        "        axis = tf.constant(1)\n", 
        "        tile_shape = (1, times, 1)\n", 
        "    else:\n", 
        "        raise ValueError(\"[ERROR]: Unknown mode for duplicate: \" + axis_mode)\n", 
        "\n", 
        "    if mode == \"train\":\n", 
        "        image_d = tf.identity(image)\n", 
        "        # image_white = tf.ones_like(image, dtype=tf.float32) * 0.999\n", 
        "        image_white = tf.random_uniform(tf.shape(image), minval=0.94, maxval=0.999, dtype=tf.float32)\n", 
        "        it = tf.constant(0)\n", 
        "        condition = lambda it, image, image_d, image_white, axis: tf.less(it, times - 1)\n", 
        "        _, _, image_d, _, _ = tf.while_loop(condition, update, (it, image, image_d, image_white, axis),\n", 
        "                                            shape_invariants=(it.get_shape(), tf.TensorShape([None, None, None]),\n", 
        "                                                              tf.TensorShape([None, None, None]),\n", 
        "                                                              tf.TensorShape([None, None, None]), axis.get_shape()))\n", 
        "    elif mode == \"val\":\n", 
        "        image_d = tf.tile(image, tile_shape)\n", 
        "    else:\n", 
        "        raise ValueError(\"[ERROR]: Unknown mode for duplicate: \" + mode)\n", 
        "\n", 
        "    return image_d\n", 
        "\n", 
        "\n", 
        "def shape(image):\n", 
        "    _shape = tf.shape(image)\n", 
        "    return _shape[0], _shape[1], _shape[2]\n", 
        "\n", 
        "\n", 
        "def process_singe_image(image_path, FLAGS):\n", 
        "    image = tf.read_file(image_path)\n", 
        "    image = tf.image.decode_png(image, channels=3)\n", 
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n", 
        "\n", 
        "    assertion = tf.assert_equal(tf.shape(image)[2], 3, message=\"image does not have 3 channels\")\n", 
        "    with tf.control_dependencies([assertion]):\n", 
        "        image = tf.identity(image)\n", 
        "\n", 
        "    # scale image, new min(height,  width) = FLAGS.image_size\n", 
        "    with tf.name_scope(\"scaling\"):\n", 
        "        h, w, _ = shape(image)\n", 
        "        scale = tf.cast(FLAGS.image_size, dtype=tf.float32) / tf.cast(tf.cond(tf.less(h, w), lambda: w, lambda: h),\n", 
        "                                                                      dtype=tf.float32)\n", 
        "        image = tf.squeeze(tf.image.resize_bilinear(tf.expand_dims(image, 0), [\n", 
        "            tf.cast(tf.floor(scale * tf.cast(h, dtype=tf.float32)), dtype=tf.int32),\n", 
        "            tf.cast(tf.floor(scale * tf.cast(w, dtype=tf.float32)), dtype=tf.int32)]))\n", 
        "        image.set_shape([None, None, 3])\n", 
        "\n", 
        "    with tf.name_scope(\"pad\"):\n", 
        "        h2, w2, _ = shape(image)\n", 
        "        h_diff, w_diff = FLAGS.image_size - h2, FLAGS.image_size - w2\n", 
        "\n", 
        "        # If uncomment, then add it control dependency\n", 
        "        # print = tf.Print(h_diff, [scale, scale_h, scale_w, h, w, h1, w1, h2, w2, h_diff, w_diff],\n", 
        "        #                  message=\"scale, h, w, h_diff, w_diff: \")\n", 
        "\n", 
        "        assert_positive_hdiff = tf.assert_greater_equal(h_diff, 0)\n", 
        "        assert_positive_wdiff = tf.assert_greater_equal(w_diff, 0)\n", 
        "        with tf.control_dependencies([assert_positive_hdiff, assert_positive_wdiff]):\n", 
        "            image = tf.pad(image, ([0, h_diff], [0, w_diff], [0, 0]), constant_values=0.999)\n", 
        "\n", 
        "    image.set_shape([FLAGS.image_size, FLAGS.image_size, 3])\n", 
        "    # image = tf.cast(image, dtype=tf.float32)\n", 
        "    return image\n", 
        "\n", 
        "\n", 
        "def pre_process(image_paths_tensor, FLAGS, mode='train'):\n", 
        "    with tf.variable_scope('pre-process', reuse=tf.AUTO_REUSE):\n", 
        "        image_batch = tf.map_fn(lambda image_path: process_singe_image(image_path, FLAGS), image_paths_tensor,\n", 
        "                                dtype=tf.float32)\n", 
        "        image_batch = tf.stack(image_batch, axis=0)\n", 
        "        print('[BATCH SHAPE]:', mode, image_batch.get_shape(), image_batch.dtype)\n", 
        "        return image_batch\n", 
        "\n", 
        "\n", 
        "def infer(net, image_path_tensor, FLAGS):\n", 
        "    with tf.variable_scope('infer'):\n", 
        "        images = pre_process(image_path_tensor, FLAGS, mode='val')\n", 
        "        return net.forward_pass(images)\n", 
        "\n", 
        "\n", 
        "def get_closest_emb_label(enrolled_emb_dic: dict, embedding_list, np_ord=2):\n", 
        "    labels = []\n", 
        "    for emb in embedding_list:\n", 
        "        min_dist = sys.maxsize\n", 
        "        closest_lab = None\n", 
        "        for l, l_emb in enrolled_emb_dic.items():\n", 
        "            dist = np.linalg.norm((emb - l_emb), ord=np_ord)\n", 
        "            if dist < min_dist:\n", 
        "                min_dist = dist\n", 
        "                closest_lab = l\n", 
        "        labels.append(closest_lab)\n", 
        "    return labels\n", 
        "\n", 
        "\n", 
        "def validate(sess: tf.Session, val_forward_pass, images_path_tensor_val, val_enroll_dict: dict, val_batch_dict: dict,\n", 
        "             FLAGS):\n", 
        "    enrolled_emb_dict = {}\n", 
        "    # _enroll_embeddings = enroll(val_forward_pass, images_path_tensor_val, FLAGS)\n", 
        "    # _embedding_list = infer(val_forward_pass, images_path_tensor_val, FLAGS)\n", 
        "    for l, images_paths in val_enroll_dict.items():\n", 
        "        _embeddings = sess.run(val_forward_pass, feed_dict={images_path_tensor_val: images_paths})\n", 
        "        enrolled_emb_dict[l] = np.mean(_embeddings, axis=0)\n", 
        "\n", 
        "    labels = []\n", 
        "    predicted = []\n", 
        "    for l, images_paths in val_batch_dict.items():\n", 
        "        embedding_list = sess.run(val_forward_pass, feed_dict={images_path_tensor_val: images_paths})\n", 
        "        labels.extend([l] * len(embedding_list))\n", 
        "        predicted.extend(get_closest_emb_label(enrolled_emb_dict, embedding_list))\n", 
        "\n", 
        "    return (np.array(labels) == np.array(predicted)).mean()\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}